## 机器学习西瓜书

#### 第一章-绪论

机器学习提供数据分析能力，云计算提供数据处理能力，众包提供数据标记能力

机器学习领域和数据库领域是数据挖掘的两大支撑

自动驾驶汽车中，机器学习起到了“司机”的作用

#### 第二章-模型评估与选择

**经验误差与过拟合**

误差均指误差期望

经验误差：学习器在训练集上的误差

泛化误差：在新样本上的误差

过拟合是机器学习面临的关键障碍，无法彻底避免，能做的只是缓解或减少其风险。

**评估方法**

使用一个`测试集`来测试学习器对新样本的判别能力，然后以测试集上的`测试误差`作为泛化误差的近似。

1. 留出法：直接将数据集D划分为两个互斥的集合，其中一个集合作为训练集S，另一个作为测试集T

2. 交叉验证法

   k=样本数量时，即特例，为留一法，但计算复杂度比较高

3. 自助法

   以自助采样法（有放回采样）为基础

   在数据集较、难以有效划分训练集/测试集时很有用

   产生的数据集改变了初始数据集的分布，会引入估计偏差

4. 调参与最终模型

   要注意，通常把学得模型在实际使用中遇到的数据称为`测试数据`，为了加以区分，模型评估与选择中用于评估测试的数据集常称为`验证集`。

   :question: 我们用测试集上的判别效果来估计模型在实际使用时的泛化能力，而把训练数据另外划分为训练集和验证集，基于验证集上的性能来进行模型选择和调参。

   个人理解：即训练集、验证集、测试集？

**性能度量**

1. 错误率与精度

2. 查准率、查全率与F1

   查准率和查全率是一对矛盾的度量，查准率高时，查全率往往偏低。

   查准率：挑出的瓜中有多少是好瓜。查全率：所有好瓜中有多少比例被挑了出来

   P-R曲线：以查准率为纵轴，查全率为横轴作图，就得到查准率-查全率曲线

   ​	若一个学习器的P-R曲线被另一个学习器的曲线完全”包住“，则说明不如后者优越。

   ​	若两个学习器的曲线发生了交叉，则一般很难断言两者孰优孰劣

   综合考虑查准率、查全率的性能度量

   ​	1.平衡点（BEP）

   ​	2.F1度量

3. ROC与AUC

4. 代价敏感错误率与代价曲线

   回归前面介绍的一些性能度量可看出，它们大都隐式地假设了均等代价，比如计算错误次数，并没有考虑不同错误会造成不同的后果。

   在非均等代价下，我们希望的不再是简单地最小化错误次数，而是希望最小化“总体代价”

**比较检验**

1. 假设检验（关于单个学习器泛化性能的假设进行检验）

   根据测试错误率估推出泛化错误率的分布

2. 交叉验证t检验

**偏差与方差**

解释学习算法泛化性能的一种重要工具

泛化误差可以分解为偏差、方差、噪声之和

​	偏差度量了学习算法的期望预测与真实结果的偏离程度，即刻画了学习算法本身的拟合能力

​	方差度量了同样大小的训练集的变动所导致的学习性能的变化，即刻画了数据扰动所造成的影响

​	噪声则表达了在当前任务上任何学习算法所能达到的期望泛化误差的下界，即刻画了学习问题本身的难度

偏差-方差分解说明：泛化性能是由学习算法的能力、数据的充分性以及学习任务本身的难度共同决定的。给定学习任务，为了取得好的泛化性能，则需使偏差较小，即能够充分拟合数据，并且使方差较小，即使得数据扰动产生的影响小。

？：t检验 $x^2​$检验

#### 第三章 线性模型

**基本形式**

线性模型试图学得一个通过属性的线性组合来进行预测的函数，
$$
即f(x) = w_1x_1+w_2x_2+...+w_dx_d+b\\
一般用向量形式写成:f(x)=w^Tx+b
$$

- $\omega$的含义：直观表达了各属性在预测中的重要性，因此线性模型有很好的可解释性。

  个人理解，即为参数

**线性回归**

`均方误差`是回归任务中最常用的性能度量。

具有非常好的几何意义，对应了常用的“欧式距离”。

`最小二乘法`：基于均方误差最小化来进行模型求解的方法

​	在线性回归中，最小二乘法就是试图找到一条直线，使所有样本到哦直线上的欧式距离之和最小

​	最小二乘用途很广，不仅限于线性回归

:question:现实任务中$X^TX$往往不是满秩矩阵，例如在许多任务中我们会遇到大量变量，其数目甚至超过样例数，导致X的列数多于行数，$X^TX$显然不满秩

线性模型虽然简单，却有丰富的变化，列入对于样例(**x**,y)，当我们希望线性模型的预测值逼近真实标记y时，就得到了线性回归模型

也可以令模型预测值逼近y的衍生物，譬如，假设我们认为示例所对应的输出标记是在指数尺度上变化，那就可将输出标记的对数作为线性模型逼近的目标，即
$$
lmy = w^Tx + b
$$
**`广义线性模型`**：

​	更一般地，考虑单调可微函数g(·)，令

​	$ y = g^{-1}(w^Tx + b)​$

​	这样得到的模型称为“广义线性模型”，其中函数g(·)称为“联系函数”

**对数机率回归**

上一节讨论如何使用线性模型进行回归学习，但若要做的是分类任务该怎么办？只需要找一个单调可微函数将分类任务的真实标记y与线性回归模型的预测值联系起来

考虑二分类任务，需要将是指z转换成0/1值，最理想的是“单位阶跃函数”，然而，单位阶跃函数不连续，因此不能直接用作上式中的$g^-(·)$

`对数机率函数`(logistic function)正是这样一个常用的替代函数
$$
y = \frac{1}{1+e^{-z}}
$$
从上式看出，实际上是在用线性回归的预测结果去逼近真实标记的对数几率，因此，其对应的模型称为‘对数几率回归“。

虽然名字是“回归”，但实际是一种分类学习方法。

:question: 先验概率、后验概率

> 事情还没有发生，要求这件事情发生的可能性的大小，是先验概率。事情已经发生，要求这件事情发生的原因是由某个因素引起的可能性的大小，是后验概率

:question:极大似然法

**线性判别分析**

LDA是一种经典的线性学习方法

思想：给定训练样例集，设法将样例投影到一条直线上，使得同类样例的投影点尽可能接近、异类样例的投影点尽可能远离；在对新样本进行分类时，将其投影到同样的这条直线上，再根据投影点的位置来确定新样本的类别

:question: 协方差矩阵

**多分类学习**

更多情形下，我们是基于一些基本策略，利用二分类学习器来解决多分类问题。

多分类学习的基本思路是”拆解法“，即将多分类任务拆为若干个二分类任务求解。本节主要介绍拆分策略，`多个分类器的集合见第8章`

最经典的拆分策略有三种：一对一、一对其余、多对多

OvO（一对一）将这N个类别两两配对，从而产生$\frac{N(N-1)}{2}$个分类任务

OvR（一对其余）每次将一个类的样例作为正例，所有其他类的样例作为反例来训练N个分类器

MvM(多对多)：每次将若干个类作为正类，若干个其他类作为反类。

​	最常用的MvM技术：“纠错输出码”（EOOC）

EOOC是将编码的思想引入类别拆分，并尽可能在解码过程中具有容错性。

**类别不平衡问题**

即指分类任务中不同类别的训练样例数目差别很大的情况。

类别不平衡学习的一个基本策略：再缩放（再平衡）

再缩放也是“代价敏感学习”的基础

多分类学习中虽然有多个类别，但每个样本仅属于一个类别，如果希望一个样本同时预测出多个类别标记，例如一幅图象同时标注为“蓝天”、“白云”、“羊群”、“自然场景”，这样的任务就不再是多分类学习，而是`多标记学习`

#### 决策树

**基本流程**

一颗决策树包含一个根节点、若干个内部节点和若干个叶节点。叶节点对应于决策结果，其他每个节点则对应于一个属性测试。每个节点包含的样本集合根据属性测试的结果被划分到子节点中。

**划分选择**

决策树学习的关键是如何选择最优划分属性

一般性而言，随着划分过程不断进行，我们希望决策树的分支节点所包含的样本尽可能属于同一类别，即节点的“纯度”越来越高。

1. 信息增益

   我们可用信息增益来进行决策树的划分属性选择

2. 增益率

   信息增益准则可能对取值数目较多的属性有所偏好，为减少这种偏好可能带来的不利影响，结合增益率来选择划分最优划分属性

3. 基尼系数

   基尼值：反映了从数据集D中随机抽取两个样本，其类别标记不一致的概率，因此Gini(D)越小，则数据集D的纯度越高。

## 吴恩达机器学习

什么是机器学习？

> 使计算机无需显式编程就能学习的研究领域。
>
> E(experience) T(tasks) P(performance)

#### 第一章

**监督学习**

给算法一个数据集，其中包含了”正确答案“

1. 回归问题

​	目标是预测一个连续值输出

2. 分类问题（两类、多类）

​	预测离散值输出

如何处理无穷多个特征/属性

**无监督学习**

给出的数据没有任何标签

1. 聚类算法

​	簇（cluster）

#### 二、单变量线性回归

----

**假设函数**

线性回归(linear regression)

向学习算法提供训练集，输出一个函数，通常用小写h表示**`假设函数`**

**代价函数**

只要我们知道了假设函数，就可以进行预测了。假设函数中有两个未知量$\theta_0,\theta_1$，当选择不同的参数时，模型的效果肯定是不一样的。因此现在的问题是该如何选择这两个参数了，因此引入代价函数的概念。

> 个人理解：代价函数用来选择参数，取使得代价函数最小的参数
>
> Hypothesis：$h_0(x)$
>
> Parameters：$\theta_0, \theta_1​$
>
> Cost Function：$J(\theta_0, \theta_1)​$
>
> Goal：minimize$J(\theta_0, \theta_1)$

平方误差代价函数（用于回归问题）

优化目标（想要代价函数最小）：
$$
minimize(\theta_0, \theta_1) J(\theta_0, \theta_1) = \frac{1}{2m}\sum_{i=1}^{m}{(h(x) - y)}^2
$$
**梯度下降**

- 思想：首先随机选择两个$\theta_0,\theta_1$（例如都为0），不断改变它们的值使得$J(\theta)$ 变小，最终找到$J(\theta)$ 的最小值点。

> 可以把梯度下降的过程想象成下山坡，如果想要尽可能快地下坡，应该每次往坡度最大的方向下山。

- 计算梯度：梯度也就是代价函数对每个$\theta$ 的偏导

$\theta_j := \theta_j - \alpha \frac{\partial(\theta_0, \theta_1)}{\partial\theta_j}​$

> $\theta_0，\theta_1​$必须**`同步更新`**，不然会出错

- 学习率$\alpha$过小会导致收敛缓慢，过大会导致不收敛

当到达局部最低点时，梯度下降相当于什么都没做，于我们的预期相符

当我们接近局部最低点时，导数值会越来越小，梯度下降将自动采取较小的幅度

可以尝试用它最小化任何代价函数，而不仅是线性回归中的代价函数 

> 事实上，用于线性回归的代价函数总是一个`凸函数`(Convex Function)，没有局部最优解，只有一个全局最优解。所以在使用梯度下降时，总会得到一个全局最优解。

**梯度下降应用到线性回归问题上---线性回归的梯度下降**

Batch梯度下降法

​	每一次梯度下降，都遍历了整个训练集的样本

另一种求解代价函数J最小值的方法：正规方程组法，之后介绍

#### 三、多变量线性回归

----

**多特征**

在之前的单变量线性回归中，我们的问题只涉及到了房子面积这一特征，然而在实际问题中会有很多特征，比如还有卧室数量$x_2$，房子楼层数$x_3$等，其中，n表示特征的数量，m表示训练样例的数量。

​	$x^{(i)}$为第i个训练样例

​	$x_j^{(i)}$为第i个训练样例的第j个特征

**假设函数**

类似单变量线性回归，现在假设函数记作
$$
h_\theta(x) = \theta_0 + \theta_1x_1+\theta_2x_2+...+\theta_nx_n 
$$
每次这样写太麻烦，为了方便，先定义$x_0=1，即x_0^{(i)}=1$，则$h(x) = \theta_0 x_0 + \theta_1 x_1 + ... + \theta_n x_n$，此时就得到了假设函数的向量表示：
$$
h(x) = \theta ^Tx
$$
**多元梯度下降法**

**多元梯度下降法演练I：特征缩放**

特征值的范围要接近，这样收敛过程会变快。并不需要太精确，只是为了让梯度下降运行的更快一点

- 均值归一化

$x_i = \frac{x_i - \mu_i}{si}，\mu_i为均值，s_i为范围（或标准差）$

**多元梯度下降法演练II：学习率**

确定梯度下降正确运行：

1. 通过绘制$J(\theta)​$随迭代步数变化的曲线图观察，迭代之后代价函数变小(倾向于)

   如果曲线是上升的，往往可以通过减小学习率$\alpha​$来实现

   如果曲线循环往复上升下降，也可以减小学习率

2. 自动收敛测试

   如果一步迭代后的下降小于1e-3，则说明已经收敛

学习率太小时，收敛(convergence)会很慢

学习率太大时，$J(\theta)​$可能不会收敛

​	尝试不同的$\alpha$值：0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1

**特征选择和多项式回归**

定义新特征有时候可能得到更好的模型

如何将一个多项式（如一个二次函数/三次函数）拟合到我们的数据上

​	$h_0(x) = \theta_0 + \theta_1(size) + \theta_2(size)^2 + \theta_3(size)^3​$

​	令$x_1 = (size), x_2 = (size)^2, x_3=(size)^3​$

​	则$h_0(x) = \theta _0 + \theta x_1 + \theta x_2 + \theta x_3​$

**正规方程**

之前我们一直使用梯度下降来求解最优值，缺点是需要进行很多次迭代才能得到全局最优解。

设计矩阵X为$m * (n +1)​$维

$\theta = (X^{T}X)^{-1}X^{T}y​$

得到的 $\theta​$ 即为使得代价函数最小的值

使用正规方程求解时可以**`不必进行特征缩放`**

**梯度下降与正规方程的选择**

梯度下降法需要选择合适的学习速率 $\alpha​$ ，并且需要很多迭代，还要画图判断敛散性，而正规方程不需要。

然而当n很大时，正规方程的速度会很慢，求解$(X^{T}X)^{-1}$的时间接近于$O(n^3)$，因此当n小于10000时，可以选择正规方程求解，当大得多时，就要考虑梯度下降或者其他方法了

使用正规方程还有一个问题就是$X^TX$可能存在不可逆的情况。这个时候可能因为我们使用了冗余的特征，或者使用了太多的特征（特征数大于样本的数量）。对于这种情况我们可以删掉一些特征或者使用正则化。

#### Logistic回归(对数机率回归)

----

需要注意的是这个模型虽然叫regression，但它是一个用来解决分类问题的模型

预测离散值

**分类**

分类问题的例子：判断一封邮件是否是垃圾邮件；判断一次金融交易是否欺诈；肿瘤恶性良性分类

不推荐将线性回归用于分类问题

​	因为对于数据集中y=0，1，而实际$h_\theta (x)​$可能大于1或者小于0

logistic回归实际上是一种分类算法

​	0<= h(x) <= 1

**假设函数** 

对数机率函数(Logistic Function)是Sigmoid函数最重要的代表，它将z值转化为一个接近0或1的y值，并且其输出值在`z=0` 附近变化很陡。Sigmoid函数即形似S的函数

由$h_\theta(x) =g(\theta^Tx)​$   $g(z) = \frac{1}{1 + e^{-z}}​$

得到
$$
h_\theta(x)=\frac{1}{1+e^{-\theta^Tx}}​
$$
$P(y = 0|x;\theta)​$ ：给定参数$\theta​$，给定特征x的条件下y=0的概率

$h_\theta(x) = P(y = 1|x;\theta)$，我们可以将对率函数的输出理解为当输入为x的时候，y=1的概率

**决策边界**

Sigmoid函数当$z\gt0$时即$g(z)\ge0.5$时即预测$y = 1$；当$z\lt0$时$g(z)\lt0.5$即预测$y=0$

而在对率回归中，   $z = \theta^Tx$，因此 $\theta^Tx = 0$时可以得到决策边界

- 决策边界是假设函数的一个属性，而不是训练集的属性，只要给定了$\theta$就确定

- 当我们有更高阶的多项式时，会得到更复杂的决策边界

**代价函数**

若将假设函数代入之前的代价函数，则代价函数成为一个非凸函数（因为logistic回归中$h_\theta(x)$是非线性的），当应用梯度下降时可能进入局部最优。

因此定义代价函数$J(\theta)​$为：
$$
J(\theta) = \frac{1}{m}Cost(h_\theta(x), y^{(i)})\\
单个样本的代价：
Cost(h_\theta(x), y) = \begin{cases}
-log(h_\theta(x)) & y = 1 \\
-log(1-h_\theta(x)) &  y = 0 
\end{cases}
$$
- 当y=1,h(x)=1时，假设函数预测正确，代价值为0，即当预测结果和真实结果一样时，我们不对学习算法进行惩罚；但当结果不一致时，即当h(x)->0时，我们对算法的惩罚趋于无穷。

这样对代价函数处理之后，我们的代价函数就是一个凸函数，可以使用梯度下降来找到一个全局最优解。

**简化的代价函数与梯度下降**

因为y的值只有0或1两种情况，现在将代价函数用一个式子表达：
$$
Cost = -ylog(h_\theta(x)) - (1 - y)log(1-h_\theta(x)) \\
J(\theta) = -\frac{1}{m}[\sum_{i=1}^my^{(i)}logh_\theta(x^{(i)}) + (1 - y^{(i)})log(1-h_\theta(x^{(i)}))]
$$
此代价函数是从统计学中的极大似然估计得来的，同时具有一个很好的性质--凸函数。

> 凸函数：判定方法可利用定义法、已知结论法以及函数的二阶导数，对于实数集上的凸函数，一般的判别方法是求它的二阶导数，如果其二阶导数在区间上非负，就称为凸函数。如果其二阶导数在区间上恒大于0，就称为严格凸函数。

因此是大部分人用来拟合logistic回归模型的代价函数

要求$minJ(\theta)​$：
$$
重复进行
\theta_j := \theta_j - \alpha \frac{\partial}{\partial\theta_j}J(\theta)\\
即:\theta_j := \theta_j - \alpha\sum_{i = 1}^m(h_\theta(x^{(i)}) - y^{(i)})x_j^{(i)}
$$
- 梯度下降的方式形式和线性回归时相同，然而$h_\theta(x)$不同，导致不同。

- 同样的，可以使用`特征缩放`来加快梯度下降收敛的速度

**高级优化**

高级优化算法的目的是无需选择学习率a，同时更快速的找到全局最小值

比梯度下降快得多得算法比如：

​	共轭下降

​	...

优化算法库会使程序变得模糊，难于调试，但会加快梯度下降的速度

例子：`fminunc()`

```matlab
options = optimset('GradObj', 'on', 'MaxIter', '100');
initalTheta = zeros(2, 1);
[optTheta, functionVal, exitFlag] = fminunc(@costFunction, initialTheta, options);
```

**多元分类**：一对多(one-vs-all)

将多个类的分类变为多个二元分类。预测时，需要计算出$h_\theta^{(1)}(x),h_\theta^{(2)}(x).h_\theta^{(3)}(x)$的值并得出最大值，其对应的分类即为预测x的分类。

#### 正则化

----

**过拟合问题**

千方百计拟合训练集，导致无法泛化到新的样本中

应对方法：

​	1.减少特征数量，可以手工选择保留哪些特征，或者使用一些模型选择的算法（后面会讲到如PCA）

​	2.正则化：保留所有特征，但是减少参数的大小

**代价函数**
$$
J(\theta) = \frac{1}{2m}[\sum_{i=1}^{m}{(h_\theta(x)^{(i)} - y^{(i)})}^2 + \lambda\sum_{j=1}^n\theta_j^2]
$$
正则化参数：控制两个不同目标之间的取舍（一般不对$\theta_0$进行改变）

​	1.想要更好的拟合数据

​	2.保持参数尽量小（从而保持模型尽量简单，避免过拟合的发生）

如果正则化参数设置太大，会使得$\theta$约等于0，即$h_\theta(x)=\theta_0$，$h_\theta(x)$就变成一条直线了，由过拟合变成欠拟合，得不偿失。所以需要选择一个合适的$\lambda$，后面的课程会讲到自动选择合适的$\lambda$ 的方法

**线性回归的正则化**

- 梯度下降

因为我们不对$\theta_0$进行惩罚，所以将$\theta_0$的单独写出来，其余参数的更新规则如下公式（j>0时）：
$$
\theta_j:=\theta_j(1-\alpha \frac{\lambda}{m}) - \alpha\frac{1}{m}\sum_{i=1}^m(h_\theta(x^{(i)})-y^{(i)})x_j^{(i)}
$$
也可以用正规方程来求解正则化线性回归模型

利用它可以避免过拟合的问题，这样可以在较小的训练集而特征较多的情况下使用

**Logistic回归的正则化**

对于逻辑回归，也可以给代价函数加一个正则化的表达式$\frac{\lambda}{2m}\sum_{j=1}^n\theta_j^2$

![logistic正则化](C:\Users\HC\Desktop\logistic正则化.png)

#### 神经网络学习（上）

----

**非线性假设**

我们之前学到的，无论是线性回归还是逻辑回归都有一个缺点，当特征太多时，计算量会非常大。

神经元与大脑

神经网络再次兴起的原因，计算能力的提升

**模型展示I**

神经元有很多输入通道（树突），它们接收来自其他神经元的信息

神经元有一条输出通道（轴突），用来给其他神经元传导信息

神经网络是大量神经元相互连接并通过电脉来交流的一个网络。

因此一个神经元是一个计算单元

激活函数：指代非线性函数`g(z)`

​	带有sigmoid函数的激活函数

**`输入层必要的时候会加一个$x_0$（为1），称为偏置单元`**

$\theta$称为模型的参数/权重

**`神经网络`**：是一组神经单元组成的集合

> 第一层为输入层（输入特征），最后一层为输出层（输出假设的最终计算结果），中间的若干层为隐藏层

- $a_i^{(j)}$ 代表`第j层第i个`神经元的激活项

​	由一个具体神经元计算并输出的值

- $\Theta^{(j)}​$权重矩阵，控制第j层到第j+1层的映射

$$
a_1^{(2)} = g(\Theta_{10}^{(1)}x_0+\Theta_{11}^{(1)}x_1+\Theta_{12}^{(1)}x_2+\Theta_{13}^{(1)}x_3)
$$

即sigmoid激活函数(也即logistic激活函数)作用在这种输出的线性组合上的结果。

>  个人理解，这种映射通过矩阵乘法实现 例如使用$\Theta^{(1)} \times a^{(1)}$ 再在g(z)的作用下即可得到$a^{(2)}$

一般地，如果神经网络在层次j上有$s_j$个单元，在层次j+1上有$s_{j+1}$个单元，则$\theta^{(j)}$控制j到j+1层之间映射的矩阵，维度为 ​$s_{j+1}*(s_j + 1)$  （因为前一层加了一个bias unit）

- z：输入单元的加权和，将simoid函数应用到z上，得到激活值即a

- a的意义：激活值

**模型展示II-前向传播算法**

我们把这样从左往右的算法称为前向传播forward propagation，其实就是由输入层计算输出的过程。这里为了提高计算的效率，我们使用向量化的算法。

- 向量化计算h(x)

首先做如下定义：

定义z为某个特定神经元的输入值$x_0,x_1,x_2,x_3..$的加权线性组合
$$
z_1^{(2)} = \Theta_{10}^{(1)}x_0 + \Theta_{11}^{(1)}x_1 + \Theta_{12}^{(1)}x_2 + \Theta_{13}^{(1)}x_3 \\
z_2^{(2)} = \Theta_{20}^{(1)}x_0 + \Theta_{21}^{(1)}x_1 + \Theta_{22}^{(1)}x_2 + \Theta_{23}^{(1)}x_3 \\
z_3^{(2)} = \Theta_{30}^{(1)}x_0 + \Theta_{31}^{(1)}x_1 + \Theta_{32}^{(1)}x_2 + \Theta_{33}^{(1)}x_3 \\
即z^{(2)} = \begin{bmatrix}z_1^{(2)}\\z_2^{(2)}\\z_3^{(2)}\end{bmatrix}
$$
这样$z^{(2)}$的计算就可以写成向量计算：$z^{(2)}=\Theta^{(1)}x$，进而有$a^{(2)} = g(z^{(2)})$，为了使后面几层的写法统一，令$a^{(1)}=x$，所以有$z^{(2)}=\Theta^{(1)}a^{(1)}$，

我们在隐藏层加上一个额外的$a_{(0)}^{(1)}= 1$，得到$a^{(2)}=\begin{bmatrix} a_0^{(2)} \\ a_1^{(2)}\\a_2^{(2)}\\ a_3^{(2)}\end{bmatrix}$，同理$z^{(3)}=\Theta^{(2)}a^{(2)}$，最后$h_\Theta(x)=a^{(3)}=g(z^{(3)})$

现在我们先把刚才的神经网络输入层盖住，观察剩下部分的结构以及算法我们发现, 其实这一部分其实就是前面所讲的logistic回归. 不同的是, 它的输入$\alpha $是由正真的特征$x$学习得到的, 可以把$\alpha $看成新的特征, $x​$看成初始特征. 这样, 神经网络就相当于通过初始特征学习到新的特征, 再通过新的特征进行logistic回归得到输出结果.

前向传播的工作原理

​	从输入层的激活项开始，前向传播到第一隐藏层，然后传播到第二隐藏层，最终到达输出层。

- 神经网络利用隐藏层计算更复杂的特征，并输入到最后的输出层，从而学习更复杂的非线性假设函数

**例子**

以神经网络如何进行逻辑运算为例

神经网络如何计算复杂的非线性假设

为何神经网络可以计算复杂的函数

​	当网络中有很多层，第二层有一些关于输入的简单函数，第三层在此基础上，计算更复杂的方程，再往后一层，计算的函数越来越复杂

视频中以手写邮编的识别为例

**多元分类**

建立一个有4个输出单元的神经网络

#### **神经网络学习（下）**

----

如何让神经网络自动学习这些参数

**代价函数**

符号定义：

- L表示神经网络的层数
- $s_l$ 第l层计算单元的个数（不包括偏置单元）
- K：输出单元数（ $ s_L$）

对于二分类问题，神经网络只需要一个输出单元，而对于多分类问题，需要K个输出单元，其中K为类的个数。

- 二元分类

最后输出层只有一个单元，输出的$h_\Theta(x)$ 是一个实数

即K=1（K为输出单元的个数）

- 多元分类

我们的假设会输出K维向量，$h_\Theta(x) \in R^K​$输出单元的个数也等于K

同时可知$K\ge3​$（否则就为二元分类了）

- 正则化时不会将偏差项正则化，正则化的也没有大影响

- 这里我们按照多分类对代价函数进行描述。对于前半部分，因为神经网络中要有K个输出，所以先要对这K个输出的损失求和；对于后半部分，因为每一层（除了输出层）都有一个$\Theta​$，所以正则化项要将这些权重都包括进来（当然，不包括bias unit的权重）

$$
h_\Theta(x) \in R^K，是一个K维的向量，我们用(h_\Theta(x))_i来代表第i个输出值 \\
$$

![神经网络代价函数](C:\Users\HC\Desktop\神经网络代价函数.png)

注：三元组中的i与第几个训练样本无关

**反向传播算法**

同样，知道代价函数之后，我们希望使用梯度下降来找到最优解。想要使用梯度下降需要求出“梯度”即偏导项$\frac{\partial}{\partial_{\Theta_{ij}}^{(l)}}J(\Theta)$，而计算这个偏导数项的过程就叫做反向传播算法。

为了计算所有参数的偏导数项，定义$\delta_j^{(l)}$为第l层第j个结点的误差

$\delta^{(L)} = a^{(L)}-y^{(i)}$，不计算$\delta^{(1)}$，因为是输入层，不存在误差

剩下每层的$\delta^{l}$为：
$$
\delta^{(3)} = (\Theta^{(3)})^T\delta^{(4)}.*g'(z^{(3)})
，其中g'(z^{(3)})=a^{(3)}.*(1-a^{(3)})
$$
求出所有的$\delta$之后，可以很容易得到我们要求的偏导项（忽略正则化）
$$
\frac{\partial}{\partial_{\Theta_{ij}^{(l)}}}J(\Theta)=a_i^{(l)}\delta_j^{(l+1)}
\\写成向量的形式即\frac{\partial}{\partial_{\Theta^{(l)}}}J(\Theta)=\delta^{(l+1)}(a^{(l)})^T
$$
完整计算过程如下：![反向传播偏导计算](C:\Users\HC\Desktop\反向传播偏导计算.png)

**使用注意：展开参数**

- 为了使用高级优化算法，这一节我们讲如何调整参数。在神经网络中，参数$\Theta^{(j)}$是一个矩阵，而在之前利用高级优化算法的课程中，我们知道$\theta$是一个向量，这个时候就需要对$\Theta$进行`unrolling`

参数的矩阵表达式和向量表达式之间的转换

```matlab
function [jVal, gradient] = costFunction(theta)
...
optTheta  = fminunc(@costFunction, initialTheta, options)

thetaVec = [ Theta1(:); Theta2(:); Theta3() ];
// 还原
Theta1 = reshape(thetaVec(1:110), 10, 11)
Theta2 = reshape(thetaVec(111:220), 10, 11)
Theta3 = reshape(thetaVec(221:231), 1, 11)
```

矩阵形式的优点：当进行前向/反向传播时更方便

向量形式的优点：当使用一些高级优化函数时，算法通常要求把所有的参数展开成一个长向量的形式

**梯度检测**

由于神经网络的复杂性，我们在使用梯度下降或其他的高级优化算法时可能会出现bug，即使感觉上好像没出什么问题。那么如何有效检查出问题呢，这时就需要使用`Gradient Checking`

即梯度检测（数值检验方法）是用来确保算法运行的正确的

我们使用以下近似：$\frac{d}{d\theta}J(\theta) \approx \frac{J(\theta + \epsilon) + J(\theta-\epsilon)}{2\epsilon}​$，通常取$\epsilon=10^{-4}​$   

上面例子中$\theta$是一个实数，$\theta$为一个向量时，用偏导数进行数值估计
$$
\frac{\partial}{\partial\theta_j}J(\theta) \approx \frac{J(\theta_1,...,\theta_j+\epsilon,...\theta_n) + J(\theta_1,...,\theta_j-\epsilon,\theta_n)}{2\epsilon}
$$

- 在实际运用中，我们使用以下代码来计算`gradApprox`，然后我们通过反向传播算法计算得来的`DVec`和`gradApprox` 进行比较，如果两个值近似的话，说明我们的反向传播算法运行地没有问题。

![梯度检测代码](C:\Users\HC\Desktop\梯度检测代码.png)

- 步骤如下

1. 运用反向传播计算Dvec（可能是$D^{(1)},D^{(2)},D^{(3)}​$这些矩阵的展开）
2. 数值上的梯度检测，计算出gradApprox
3. 确定两者的值相近（相等或差几位小数）
4. 一旦确定反向传播的实现是正确的，关掉梯度检测（因为梯度检测比反向传播计算导数要慢的多），继续运行反向传播

**随机初始化**

任何优化算法都需要一些初始值，对于逻辑回归我们将$\theta$ 设为0是可行的，但对于神经网络来说不行，这样会使得第二层所有激活单元都会有相同的值。当然，设成一样的非0值结果相同。

对于$\theta^{(1)} \in R^{10\times11}$，使用随机函数来进行初始化：(设置为$[-\epsilon,\epsilon]$之间的值)

```matlab
Theta1 = rand(10, 11) * (2 * INIT_EPSILON) - INIT_EPSILON 
```

总结，为了训练神经网络，应首先将权重随机初始化为一个接近0的，范围在$[-\epsilon, \epsilon]​$之间的数，然后进行反向传播，进行梯度检测，最后使用梯度下降或其他高级优化算法来最小化代价函数J（关于$\Theta​$的函数）

**组合到一起**

输入单元个数：特征$X^{(i)}​$的维度

输出单元个数：对于多元分类问题，类别个数

隐藏层的选择：合理的默认情况为1个隐藏层，或者多于1个隐藏层，隐藏层的单元个数相同。

​	隐藏层单元数量越多越好，但多的时候计算量一般会比较大

训练神经网络的步骤：

 	1. 随机初始化权重
 	2. 执行前向传播，对任意一个$x^{(i)}$计算出$h(x^{(i)})$，即一个输出值y的向量
 	3. 计算代价函数$J(\Theta)$
 	4. 执行反向传播计算偏导数项（对所有样本使用for循环实现）
 	5. 进行梯度检查，然后禁用梯度检查
 	6. 使用梯度下降或高级优化算法，将这些优化算法与反向传播向结合来最小化$J(\Theta)$

反向传播的目的是算出梯度下降的方向，梯度下降的作用是沿着这个方向一点点下降直到我们想要的点

基本原理：试图找到某个$\Theta$最优的参数使得神经网络的输出值与训练集中观测到的$y^{(i)}$的实际值尽可能地接近

#### 应用机器学习的建议

**决定下一步做什么**

问题：加入得到学习参数后，将假设函数放到一组新的房屋样本上进行测试，预测房价时产生了很大的误差

机器学习诊断法：通过执行这些测试能够了解算法在哪里出了问题，也能告诉你，要想改进一种算法的效果，什么样的尝试是有意义的。提早发现哪些方法是无效的

**评估假设**

分成训练集和测试集（7：3），随机选择

步骤：首先从训练数据学习得到参数$\Theta $，之后计算测试集误差

**模型的选择和训练、验证、测试集**

因为之前将数据集分为训练集和测试集，用测试集来选择模型，然后仍在测试集上计算误差，将其作为理想的泛化误差，建议不要这样做。更好的选择如下：

将数据集分为`训练集`，`交叉验证集`，`测试集`

使用交叉验证集进行选择最合适的模型，并使用测试集进行评估

**诊断偏差与方差**

如果一个机器学习算法表现得不好，往往是因为欠拟合或过拟合 

bias vs. variance

高偏差（欠拟合）：训练误差$J_{train}(\theta)​$高，验证误差$J_{cv}(\theta)​$也高

高方差（过拟合）：训练误差$J_{train}(\theta)​$很小，验证误差$J_{cv}(\theta)​$远远高于训练误差

**正则化和偏差、方差**

$\lambda​$很大则可能处于欠拟合：对$\theta_1....\theta_n​$都用了很大的惩罚值，最后$h_\theta(x)​$约等于$\theta_0 ​$

$\lambda​$很小时则可能处于过拟合：因为基本忽略正则化

**学习曲线**

学习曲线用于判断一个学习算法是否处于偏差、方差或者两者都有。

**`在改进算法之前，往往先画出学习曲线来判断是什么问题`**

如果一个算法处于高偏差，选用更多的训练数据对于改善算法表现并无作用

如果一个算法处于高方差，获得更多的训练数据对改进算法是有帮助的

**决定下一步做什么**

改进一个机器学习算法时：

- 获得更多的训练样例：修复高方差
- 尝试更小的特征集：修复高方差
- 尝试附加特征：修复高偏差
- 增加多项式特征($x_1^2,x_2^2,x_1x_2,etc$）：修复高偏差
- 减小$\lambda$：修复高偏差
- 增大$\lambda$：修复高方差

#### 机器学习系统设计

**确定执行的优先级**

即确定选定什么方案值得花上时间去研究

如何区分是否为垃圾邮件

​	首先想的是如何表示邮件的特征向量X，结合分类标签y，就能训练一个分类器

**误差分析**

先粗暴的实现一个简单的算法，再去改进

数值评估去衡量效果

强烈建议在交叉验证集上做误差分析

**不对称性分类的误差评估**

**`偏斜类`**：一个类中的样本数比另一个类的数据多很多，因此通过总是预测y=1或y=0，算法可能表现非常好，因此使用分类误差（精确度accuracy）作为评估度量会出现问题。

因此我们要选择别的误差度量值，其中一种是`查准率`/`召回率`（以数量较少的那个类作为y=1）

分为`真阳性TP`，`真阴性TN`，`假阳性FP`、`假阴性FN`

precision:$查准率 = \frac{true \ pos}{true \  pos + false \ pos}​$

查准率越高越好

Recall:$召回率 = \frac{true \ pos}{true \ pos + false \ neg}​$

如果所有病人确实得了癌症，有多少人我们能够正确告诉他们需要治疗

这样一个总是预测y=0的评估模型中，召回率为0，这样的模型不会有高查准率和高查全率，即算法不能总是预测y=1或0来欺骗我们

> TP真正：将正类预测为正类数；TN真负：将负类预测为负类数
>
> FP假正：将负类预测为正类数（误报）；FN假负：将正类预测为负类数（漏报）
>
> 精确率precision定义为：$P=\frac{TP}{TP+FP}$。精确率是针对我们`预测结果`而言的，它表示预测为正的样本中有多少是对的。
>
> 召回率recall定义为：$R=\frac{TP}{TP+FN}$。召回率是针对我们原来的`样本`而言的，表示的是样本中的正例有多少被预测正确了。
>
> 精确率precision和准确率accuracy是不一样的。$ACC=\frac{TP+TN}{TP+TN+FP+FN}$（正负样本不平衡的情况下，accuracy这个评价指标有很大缺陷。

**查准率和召回率的平衡**

取决你想要高查准率，低召回率还是高召回率，低查准率，来选择：

$Predict \ 1 \ if \ h_\theta(x) \ge threshod$

F值公式（结合precision和recall给出一个评估度量值）
$$
F_1\ Score = 2 \frac{PR}{P + R}
$$
**机器学习数据**

如果有大量的数据，并且训练了一个带有很多参数的学习算法，会是一个很好的方式来提供一个高性能的学习算法

#### 支持向量机

  **优化目标**
$$
minC\sum_{i=1}^n[y^{(i)}cost_1(\theta^Tx^{(i)})+(1-y^{(i)})cost_0(\theta^Tx^{(i)})] + \frac{1}{2}\sum_{i=1}^n\theta_j^2
$$
cost_1用于正样本

$CA+B$，通过调整C的值来权衡A和B的权重

与logistic回归不同的是，支持向量机不会输出概率，相对的我们得到的是通过优化这个函数得到一个参数$\theta$

**直观上对大间隔的理解**

SVM也叫大间隔分类器：尽量把正样本和负样本以最大的间距分开 

支持向量机的间距：

C起的作用就像$\frac{1}{\lambda}$（正则化参数）

**大间隔分类器的数学原理**

向量内积

目标优化函数
$$
min\frac{1}{2}\sum_{j=1}^n\theta_j^2\\
 	s.t.\ p^{(i)}||\theta|| \ge 1 \ if\ y^{(i)} = 1\\
	p^{(i)}||\theta|| \le -1 \quad if\ y^{(i)} = 0\\
	||\theta||代表\theta的长度length/范数norm
$$
为什么SVM会是一个大间隔分类器？

正样本和负样本之间的间隔的值即$p^{(i)}$的值，通过使他们的值变大，即间距变大，SVM最终可以输出一个较小的$\theta$的值，这就是支持向量机优化目标函数所做的，这也使为何SVM最终会找到大间距分类器的原因，因为它试图最大化这些$p^{(i)}$的范数，也就是训练样本到决策边界的距离.

**核函数1**

构造复杂的非线性分类器

这些不同的相似度量函数即为核函数（此处为高斯核）

通过**`标记`**点和**`相似性函数`**来定义新的特征变量，从而训练复杂的非线性边界
$$
f_1 = similarity(x, l^{(1)}) = exp(-\frac{||x-l^{(1)}||^2}{2\sigma^2})\\
if \ x\approx l^{(1)}: \ f_1 \approx 1\\
if \ x \ is \ far \ from \ l^{(i)}: f_1 \approx0\\
$$
**核函数2**

- 如何选取标记点

  将训练样本直接选为标记点

- 当给定核函数和相似度函数后，如何使用SVM

  给定$x$，计算特征$f \in R^{m+1}$

  ​	已知$\theta$后，**Predict y = 1 if $\theta^Tf \ge 0$**，$\theta \in R^{m+1}$

  从下式获得$\theta$ ，通过解决最小化问题获得

$$
minC\sum_{i=1}^n[y^{(i)}cost_1(\theta^Tf^{(i)})+(1-y^{(i)})cost_0(\theta^Tf^{(i)})] + \frac{1}{2}\sum_{i=1}^n\theta_j^2
$$

不建议自己写代码来实现求解$\theta$，只需调用相关库函数

- SVM参数的选择：

  $C(=\frac{1}{\lambda})$的选择：

  Large C(small $\lambda$)：相当于没有正则化，则低偏差，高方差

  Small C(large $ \lambda $)：高偏差，低方差

  $\sigma^2$的选择：

  Large：高斯核函数倾向于变得平缓，特征$f_i​$变化平滑，导致高偏差，低方差

  Small：特征的变化会变得不平滑，会有较大的斜率，导致低偏差，高方差

**使用SVM**

尽管不需要写实现，要选择`参数C`以及选择`核函数(相似度函数)`

1. 不适用核函数的SVM也叫做线性核

2. 当选用高斯核时，又面临$\sigma^2$的选择。

   当n小m大时，想用核函数拟合相当复杂的非线性决策边界，可以选用高斯核

当选用高斯核的时候，要先进行特征缩放，不然式子中的间距都会由其中个别特征决定。要使SVM考虑到所有的特征变量

其他核函数：

核函数需要满足默塞尔定理

很多现成的核函数：如多项式核函数，还有一些难懂的核函数：字符串核函数（文本分类）、卡方核函数等等

- 多元分类：使用SVM包内置的或者使用one-vs-all方法

Logistic regression vs. SVMs

​	n为特征数量($x\in R^{n+1}$)，m为训练样本数目

​	n相对于m足够大时，使用logstic或者线性核函数的SVM

​	n小，m适中时，使用高斯核的SVM

​	n小，m很大时，此时高斯核会运算的很慢，此时可以手动创建更多特征，然后使用logstic或者线性核（即不带核函数）的SVM

SVM具有的优化问题是一种凸优化问题，好的SVM软件包总能找到全局最小值或者接近它的值

为何这里不用神经网络，因为训练会比较慢

------

#### 编程作业篇

:question: 向量化计算$\theta​$

**编程作业二**

```matlb
logistic regression
1.y为列向量，pos = find(y==1)返回一个列向量，为y==1的indices
2.括号()用于引用数组的元素，比如X(pos, 1)代表取所有下标对应的行的第一列
3.矩阵点乘代表每一个元素对应相乘，要求两矩阵维度相等
4.使用fminunc，不需要手动写任何循环，也不需要设置学习率，只需要提供一个计算cost和gradient的函数
regularized logistic regression

```

**logistic regression仅能够找出一个线性的决策边界**

`mapFeature.m`将两个特征的向量转换为有28个特征的高维向量，基于这个高维特征向量训练出的分类器将有一个更加复杂的决策边界

扩展内容：

 看`plotDecisionBoundary.m`是如何画决策界限的

**编程作业三**

1.logistic regression向量化的技巧

当实现对正则化逻辑回归的向量化时，有时候会仅仅对$\theta​$中的某些元素进行更新或求和。

```cpp
1.用法示例：
A(:, 1:3) = B(:, 1:3);
2.在索引的时候可以使用关键字：`end`
A(:, 2:end);
3.结合sum和.^操作符的使用：
sum(z(2:end) .^ 2)
```

2.多元逻辑回归：sone-vs-all classification

当训练第k (k$\in [1, K]$个分类器时，会需要一个m维的向量y，$y_i \in [0, 1]$，代表第i个训练样例是否为class k，因此会需要logical array

matalb logical数组

```matlab
a = 1:10;
b = 3;
a == b
 结果为输出
 1×10 logical 数组
 0   0   1   0   0   0   0   0   0   0
```

matlab max函数用法

```matlab
max(A, [], dim) 返回A中由dim指定的维数范围的最大值
例如：[Y,I] = max(A,[],1)，取每列最大值，结果存在Y里，I里存的是每列最大值的行位置。返回的是行向量
```

3.神经网络Neural Neworks

本周的编程作业使用已经训练好的参数，使用此参数执行前向传播进行预测

下周将写反向传播来学习神经网络参数



## 线性代数

**矩阵和向量**

**加法和标量乘法**

**矩阵向量乘法**

​	解决预测问题，一行代码，让数据矩阵和参数矩阵相乘

**矩阵乘法**

可以将大量的运算打包成一次矩阵乘法

**矩阵乘法特征**

​	不满足交换律

​	满足结合律 $A\times (B \times C) = (A\times B) \times C​$

​	单位矩阵相当于实数范围内1的作用

**矩阵的逆**inverse

​	方阵才有逆矩阵

​	$AA^{-1} = A^{-1}A =  I$

​	如果A中所有元素为0，则其没有逆矩阵

​	没有逆矩阵的矩阵也称为`奇异矩阵`或`退化矩阵`（可看成非常接近于0）

**矩阵的转置**transpose

$A^T$

## 所遇到相关知识

**西瓜书**

独立同分布

概率密度函数

**吴恩达**

什么样的矩阵有逆矩阵

偏导